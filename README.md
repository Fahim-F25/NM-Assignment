# NM-Assignment
<br>
# ðŸ“˜ README Description

-----01-----

## Logistic Regression Optimization using Gradient Descent and Newtonâ€™s Method

This project demonstrates the implementation and comparison of two popular optimization techniques â€” **Gradient Descent** and **Newtonâ€™s Method** â€” for minimizing the cost function of a **Logistic Regression** model.

-----02-----
### ðŸ”¹ Key Features

* Generates a *synthetic binary classification dataset* using scikit-learn.
* Implements logistic regression cost function with:

  * *Sigmoid function*
  * *Cost calculation (Negative Log-Likelihood)*
  * *Gradient computation*
  * *Hessian computation* (for Newtonâ€™s method)
* Optimizes logistic regression parameters (Î¸) using:
